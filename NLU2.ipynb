{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (second assignment NLU)\n",
    "\n",
    "* Student name: Gaia Trebucchi\n",
    "* Student number: 224464\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load `en_core_web_sm` with `spacy.load`. This will return a `Language` object stored as `nlp_spacy` containing all components and data needed to process text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "nlp_spacy=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the module conll.py provided at the following link https://github.com/esrel/NLU.Lab.2021/blob/master/src/conll.py is inserted, in order to avoid the necessity of importing it. From this module the function `read_corpus_conll` will be used as starting point to load the dataset and the function `evaluate` will be used for the first and the third request in order to report the precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\"\"\"\n",
    "Modified version of https://pypi.org/project/conlleval/\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def stats():\n",
    "    return {'cor': 0, 'hyp': 0, 'ref': 0}\n",
    "\n",
    "\n",
    "def evaluate(ref, hyp, otag='O'):\n",
    "    # evaluation for NLTK\n",
    "    aligned = align_hyp(ref, hyp)\n",
    "    return conlleval(aligned, otag=otag)\n",
    "\n",
    "\n",
    "def align_hyp(ref, hyp):\n",
    "    # align references and hypotheses for evaluation\n",
    "    # add last element of token tuple in hyp to ref\n",
    "    if len(ref) != len(hyp):\n",
    "        raise ValueError(\"Size Mismatch: ref: {} & hyp: {}\".format(len(ref), len(hyp)))\n",
    "\n",
    "    out = []\n",
    "    for i in range(len(ref)):\n",
    "        if len(ref[i]) != len(hyp[i]):\n",
    "            raise ValueError(\"Size Mismatch: ref: {} & hyp: {}\".format(len(ref), len(hyp)))\n",
    "        out.append([(*ref[i][j], hyp[i][j][-1]) for j in range(len(ref[i]))])\n",
    "    return out\n",
    "\n",
    "\n",
    "def conlleval(data, otag='O'):\n",
    "    # token, segment & class level counts for TP, TP+FP, TP+FN\n",
    "    tok = stats()\n",
    "    seg = stats()\n",
    "    cls = {}\n",
    "\n",
    "    for sent in data:\n",
    "\n",
    "        prev_ref = otag      # previous reference label\n",
    "        prev_hyp = otag      # previous hypothesis label\n",
    "        prev_ref_iob = None  # previous reference label IOB\n",
    "        prev_hyp_iob = None  # previous hypothesis label IOB\n",
    "\n",
    "        in_correct = False  # currently processed chunks is correct until now\n",
    "\n",
    "        for token in sent:\n",
    "\n",
    "            hyp_iob, hyp = parse_iob(token[-1])\n",
    "            ref_iob, ref = parse_iob(token[-2])\n",
    "\n",
    "            ref_e = is_eoc(ref, ref_iob, prev_ref, prev_ref_iob, otag)\n",
    "            hyp_e = is_eoc(hyp, hyp_iob, prev_hyp, prev_hyp_iob, otag)\n",
    "\n",
    "            ref_b = is_boc(ref, ref_iob, prev_ref, prev_ref_iob, otag)\n",
    "            hyp_b = is_boc(hyp, hyp_iob, prev_hyp, prev_hyp_iob, otag)\n",
    "\n",
    "            if not cls.get(ref) and ref:\n",
    "                cls[ref] = stats()\n",
    "\n",
    "            if not cls.get(hyp) and hyp:\n",
    "                cls[hyp] = stats()\n",
    "\n",
    "            # segment-level counts\n",
    "            if in_correct:\n",
    "                if ref_e and hyp_e and prev_hyp == prev_ref:\n",
    "                    in_correct = False\n",
    "                    seg['cor'] += 1\n",
    "                    cls[prev_ref]['cor'] += 1\n",
    "\n",
    "                elif ref_e != hyp_e or hyp != ref:\n",
    "                    in_correct = False\n",
    "\n",
    "            if ref_b and hyp_b and hyp == ref:\n",
    "                in_correct = True\n",
    "\n",
    "            if ref_b:\n",
    "                seg['ref'] += 1\n",
    "                cls[ref]['ref'] += 1\n",
    "\n",
    "            if hyp_b:\n",
    "                seg['hyp'] += 1\n",
    "                cls[hyp]['hyp'] += 1\n",
    "\n",
    "            # token-level counts\n",
    "            if ref == hyp and ref_iob == hyp_iob:\n",
    "                tok['cor'] += 1\n",
    "\n",
    "            tok['ref'] += 1\n",
    "\n",
    "            prev_ref = ref\n",
    "            prev_hyp = hyp\n",
    "            prev_ref_iob = ref_iob\n",
    "            prev_hyp_iob = hyp_iob\n",
    "\n",
    "        if in_correct:\n",
    "            seg['cor'] += 1\n",
    "            cls[prev_ref]['cor'] += 1\n",
    "\n",
    "    return summarize(seg, cls)\n",
    "\n",
    "\n",
    "def parse_iob(t):\n",
    "    m = re.match(r'^([^-]*)-(.*)$', t)\n",
    "    return m.groups() if m else (t, None)\n",
    "\n",
    "\n",
    "def is_boc(lbl, iob, prev_lbl, prev_iob, otag='O'):\n",
    "    \"\"\"\n",
    "    is beginning of a chunk\n",
    "    supports: IOB, IOBE, BILOU schemes\n",
    "        - {E,L} --> last\n",
    "        - {S,U} --> unit\n",
    "    :param lbl: current label\n",
    "    :param iob: current iob\n",
    "    :param prev_lbl: previous label\n",
    "    :param prev_iob: previous iob\n",
    "    :param otag: out-of-chunk label\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    boc = False\n",
    "\n",
    "    boc = True if iob in ['B', 'S', 'U'] else boc\n",
    "    boc = True if iob in ['E', 'L'] and prev_iob in ['E', 'L', 'S', otag] else boc\n",
    "    boc = True if iob == 'I' and prev_iob in ['S', 'L', 'E', otag] else boc\n",
    "\n",
    "    boc = True if lbl != prev_lbl and iob != otag and iob != '.' else boc\n",
    "\n",
    "    # these chunks are assumed to have length 1\n",
    "    boc = True if iob in ['[', ']'] else boc\n",
    "\n",
    "    return boc\n",
    "\n",
    "\n",
    "def is_eoc(lbl, iob, prev_lbl, prev_iob, otag='O'):\n",
    "    \"\"\"\n",
    "    is end of a chunk\n",
    "    supports: IOB, IOBE, BILOU schemes\n",
    "        - {E,L} --> last\n",
    "        - {S,U} --> unit\n",
    "    :param lbl: current label\n",
    "    :param iob: current iob\n",
    "    :param prev_lbl: previous label\n",
    "    :param prev_iob: previous iob\n",
    "    :param otag: out-of-chunk label\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    eoc = False\n",
    "\n",
    "    eoc = True if iob in ['E', 'L', 'S', 'U'] else eoc\n",
    "    eoc = True if iob == 'B' and prev_iob in ['B', 'I'] else eoc\n",
    "    eoc = True if iob in ['S', 'U'] and prev_iob in ['B', 'I'] else eoc\n",
    "\n",
    "    eoc = True if iob == otag and prev_iob in ['B', 'I'] else eoc\n",
    "\n",
    "    eoc = True if lbl != prev_lbl and iob != otag and prev_iob != '.' else eoc\n",
    "\n",
    "    # these chunks are assumed to have length 1\n",
    "    eoc = True if iob in ['[', ']'] else eoc\n",
    "\n",
    "    return eoc\n",
    "\n",
    "\n",
    "def score(cor_cnt, hyp_cnt, ref_cnt):\n",
    "    # precision\n",
    "    p = 1 if hyp_cnt == 0 else cor_cnt / hyp_cnt\n",
    "    # recall\n",
    "    r = 0 if ref_cnt == 0 else cor_cnt / ref_cnt\n",
    "    # f-measure (f1)\n",
    "    f = 0 if p+r == 0 else (2*p*r)/(p+r)\n",
    "    return {\"p\": p, \"r\": r, \"f\": f, \"s\": ref_cnt}\n",
    "\n",
    "\n",
    "def summarize(seg, cls):\n",
    "    # class-level\n",
    "    res = {lbl: score(cls[lbl]['cor'], cls[lbl]['hyp'], cls[lbl]['ref']) for lbl in set(cls.keys())}\n",
    "    # micro\n",
    "    res.update({\"total\": score(seg.get('cor', 0), seg.get('hyp', 0), seg.get('ref', 0))})\n",
    "    return res\n",
    "\n",
    "\n",
    "def read_corpus_conll(corpus_file, fs=\"\\t\"):\n",
    "    \"\"\"\n",
    "    read corpus in CoNLL format\n",
    "    :param corpus_file: corpus in conll format\n",
    "    :param fs: field separator\n",
    "    :return: corpus\n",
    "    \"\"\"\n",
    "    featn = None  # number of features for consistency check\n",
    "    sents = []  # list to hold words list sequences\n",
    "    words = []  # list to hold feature tuples\n",
    "\n",
    "    for line in open(corpus_file):\n",
    "        line = line.strip()\n",
    "        if len(line.strip()) > 0:\n",
    "            feats = tuple(line.strip().split(fs))\n",
    "            if not featn:\n",
    "                featn = len(feats)\n",
    "            elif featn != len(feats) and len(feats) != 0:\n",
    "                raise ValueError(\"Unexpected number of columns {} ({})\".format(len(feats), featn))\n",
    "\n",
    "            words.append(feats)\n",
    "        else:\n",
    "            if len(words) > 0:\n",
    "                sents.append(words)\n",
    "                words = []\n",
    "    return sents\n",
    "\n",
    "\n",
    "def get_chunks(corpus_file, fs=\"\\t\", otag=\"O\"):\n",
    "    sents = read_corpus_conll(corpus_file, fs=fs)\n",
    "    return set([parse_iob(token[-1])[1] for sent in sents for token in sent if token[-1] != otag])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request 1: \n",
    "#### Evaluate spaCy NER on CoNLL 2003 data (provided)\n",
    "* **1.1:** Report token-level performance (per class and total): accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy)\n",
    "* **1.2:** Report CoNLL chunk-level performance (per class and total): precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's analyse the function `get_sentences`:\n",
    "* **input**: the CoNLL file name from which we want to extract the true name entity labels\n",
    "* **output**: \n",
    "    * a list containing all the sentences reconstructed by the dataset\n",
    "    * a list of tuples, where the first element of the tuple is the text of the token and the second element is the name entity in the CoNLL format extracted from the dataset file\n",
    "    \n",
    "First, the provided function `read_corpus_conll` is called to store each sentence in a list of tuples, each containing a single line (corresponding to a single token and the referred labels) of the text.\n",
    "Then, two list are created to store both the string sentences and the true name entity labels extracted from the file. For each line in the output of `read_corpus_conll` the function behaves in that way:\n",
    "* a string is created to store the text of the tokens inside the sentence under observation and a list is created to store the pairs token text and name entity label\n",
    "* for each tuple (containing all the information about a single token) a list containing the information is created. If the first element of the list (the element that represents the token text) is different from '-DOCSTART-', a tuple containing the token text and its name entity label is added to `conll_sentence` list and the first element (the token text) is also added to the `sentence` along with a space to recreate the sentence.\n",
    "* If the sentence is not empty the string sentence and the list of conll tuples are respectively added to `sentences` list and `conll` list as new elements. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(file):\n",
    "    sents=read_corpus_conll(file)\n",
    "    sentences=[]\n",
    "    conll=[]\n",
    "    for sent in sents:\n",
    "        sentence=\"\"\n",
    "        conll_sentence=[]\n",
    "        for tupl in sent:\n",
    "            list_conll=(tupl[0]).split()\n",
    "            if list_conll[0]!='-DOCSTART-':\n",
    "                conll_sentence.append((list_conll[0],list_conll[-1]))\n",
    "                sentence+=list_conll[0]+\" \"\n",
    "        if len(sentence)!=0:\n",
    "            sentences.append(sentence)\n",
    "            conll.append(conll_sentence)\n",
    "    return sentences, conll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The funcion `post_fix_tokenization` is used to deal with the different segmentation done by spacy parser with respect to the dataset segmentation of tokens. It also deals with the compound dependency issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_fix_tokenization(sentence,compound=False):\n",
    "    doc=nlp_spacy(sentence)\n",
    "    new_list=[]\n",
    "    successive_compound=[]\n",
    "    for token in doc:\n",
    "        index=token.i\n",
    "        if index!=0 and doc[index-1].whitespace_=='':\n",
    "            new_list[-1][0]+=token.text\n",
    "        else:\n",
    "            if compound==False:\n",
    "                new_list.append([token.text,token.ent_iob_,token.ent_type_,token])\n",
    "            else:\n",
    "                if token in successive_compound:\n",
    "                    new_list.append([token.text,\"I\",token.ent_type_,token])\n",
    "                else:\n",
    "                    new_list.append(get_compound(token)[0])\n",
    "                    successive_compound.append(get_compound(token)[1])\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `spacy_to_conll` function is made to re-label the name entity recognized in the CoNLL format starting from the NER label of spacy. \n",
    "* **input**: a list of lists, where the outer list is referred to a sentence and the inner list are referred to the tokens of the sentence and store, in order, the token text, the token iob label of spacy, the token entity label of spacy and the token itself\n",
    "* **output**: a list of tuples where the first element is the token text and the second element is the name entity label of the token obtained by converting the spacy name entity label to the CoNLL neme entity label that more represents it.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_to_conll(list_of_tok):\n",
    "    new_list=[]\n",
    "    for token in list_of_tok:\n",
    "        if token[2]=='ORG':\n",
    "            new_list.append((token[0],token[1]+\"-\"+token[2]))\n",
    "        elif token[2]=='PERSON':\n",
    "            new_list.append((token[0], token[1]+\"-\"+'PER'))\n",
    "        elif token[2]=='GPE' or token[2]=='LOC' or token[2]=='FAC':\n",
    "            new_list.append((token[0], token[1]+\"-\"+'LOC'))\n",
    "        elif token[2]=='NORP' or token[2]=='PRODUCT' or token[2]=='EVENT' or token[2]=='WORK_OF_ART' or token[2]=='LANGUAGE' or token[2]=='TIME':\n",
    "            new_list.append((token[0],token[1]+\"-\"+'MISC'))  \n",
    "        else:\n",
    "            new_list.append((token[0], 'O'))\n",
    "        \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `my_conll` is used to combine `spacy_to_conll` and `post_fix_tokenization`, to set to True/False the compound analysis and finally  obtain the prediction of spacy for all the tokens and all the sentences of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_conll(text,compound=False):\n",
    "    my_conll=[]\n",
    "    if compound==False:\n",
    "        for sent in text:\n",
    "            my_conll.append(spacy_to_conll(post_fix_tokenization(sent)))\n",
    "    else:\n",
    "        for sent in text:\n",
    "            my_conll.append(spacy_to_conll(post_fix_tokenization(sent,True)))\n",
    "    return my_conll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we extract the prediction for the test set and the train set of CoNLL 2003 dataset. The prediction are stored in a list of lists (output of `my_conll`), where the outer list represents the entire document, and the inner lists represent the sentences according to the division done by `read_corpus_conll`. The elements of the inner lists are tuples whose first element is the token text and the second element is the name entity prediction by spacy NER (then post-processed by the functions described above to match the token segmentation in the dataset and the name entity labels). With `get_sentences` we exctract both the list of sentence to feed `my_conll` functions and the true name entity labels (the structure of this output is the same as the output of `my_conll`, a list of lists where the elements of the inner lists are tuples whose first element is the token text and the second element is the true name entity label extract by the ConLL 2003 dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_test,conll_test=get_sentences(\"test.txt\")\n",
    "my_conll_test=my_conll(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train,conll_train=get_sentences(\"train.txt\")\n",
    "my_conll_train=my_conll(sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(my_conll,true_conll):\n",
    "    acc={'O':[0,0],'B-PER':[0,0],'I-PER':[0,0],'B-ORG':[0,0],'I-ORG':[0,0],'B-MISC':[0,0],\n",
    "         'I-MISC':[0,0],'B-LOC':[0,0],'I-LOC':[0,0],'total':[0,0]}\n",
    "    for i in range(0,len(my_conll)):\n",
    "        for j in range(0,len(my_conll[i])):\n",
    "            if my_conll[i][j][1]==true_conll[i][j][1]:\n",
    "                acc[my_conll[i][j][1]][0]+=1\n",
    "                acc[my_conll[i][j][1]][1]+=1\n",
    "                acc['total'][0]+=1\n",
    "                acc['total'][1]+=1\n",
    "            else:\n",
    "                acc[true_conll[i][j][1]][1]+=1\n",
    "                acc['total'][1]+=1\n",
    "    for key in acc.keys():\n",
    "        print((key+\" accuracy=\"+str(acc[key][0]/acc[key][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_token(my_conll,true_conll):\n",
    "    positive=0\n",
    "    total=0\n",
    "    for i in range(0,len(my_conll)):\n",
    "        for j in range(0,len(my_conll[i])):\n",
    "            if my_conll[i][j][1]==true_conll[i][j][1]:\n",
    "                positive+=1\n",
    "                total+=1\n",
    "            else:\n",
    "                total+=1\n",
    "    print((\"accuracy:\"+str(positive/total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O accuracy=0.9752628969548313\n",
      "B-PER accuracy=0.6289424860853432\n",
      "I-PER accuracy=0.7880622837370242\n",
      "B-ORG accuracy=0.3070439494280554\n",
      "I-ORG accuracy=0.5149700598802395\n",
      "B-MISC accuracy=0.5584045584045584\n",
      "I-MISC accuracy=0.35648148148148145\n",
      "B-LOC accuracy=0.6822541966426858\n",
      "I-LOC accuracy=0.5603112840466926\n",
      "total accuracy=0.9043609346398191\n",
      "accuracy:0.9043609346398191\n"
     ]
    }
   ],
   "source": [
    "accuracy(my_conll_test,conll_test)\n",
    "accuracy_token(my_conll_test,conll_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O accuracy=0.9794489851277878\n",
      "B-PER accuracy=0.6683333333333333\n",
      "I-PER accuracy=0.8248674911660777\n",
      "B-ORG accuracy=0.3167220376522702\n",
      "I-ORG accuracy=0.5491360691144709\n",
      "B-MISC accuracy=0.5695171611401978\n",
      "I-MISC accuracy=0.21818181818181817\n",
      "B-LOC accuracy=0.6929971988795518\n",
      "I-LOC accuracy=0.6136560069144339\n",
      "total accuracy=0.9141640596991469\n",
      "accuracy:0.9141640596991469\n"
     ]
    }
   ],
   "source": [
    "accuracy(my_conll_train,conll_train)\n",
    "accuracy_token(my_conll_train,conll_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To report CoNLL chunk-level performance (per class and total) the evaluate function provided by the conll.py module is used to compute the precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total. The references are the true labels of the test set (and successively train set) and the hypothesis are the labels obtain by spacy NER (with all the post-processing explained above) on the test set (and successively train set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.464105</td>\n",
       "      <td>0.276340</td>\n",
       "      <td>0.346415</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>0.638614</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.591743</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>0.747832</td>\n",
       "      <td>0.672062</td>\n",
       "      <td>0.707925</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>0.774193</td>\n",
       "      <td>0.608534</td>\n",
       "      <td>0.681440</td>\n",
       "      <td>1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.676060</td>\n",
       "      <td>0.522486</td>\n",
       "      <td>0.589434</td>\n",
       "      <td>5648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              p         r         f     s\n",
       "ORG    0.464105  0.276340  0.346415  1661\n",
       "MISC   0.638614  0.551282  0.591743   702\n",
       "LOC    0.747832  0.672062  0.707925  1668\n",
       "PER    0.774193  0.608534  0.681440  1617\n",
       "total  0.676060  0.522486  0.589434  5648"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs_test=conll_test\n",
    "hyps_test=my_conll_test\n",
    "results_test = evaluate(refs_test, hyps_test)\n",
    "pd_tbl_test = pd.DataFrame().from_dict(results_test, orient='index')\n",
    "pd_tbl_test.round(decimals=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>0.669024</td>\n",
       "      <td>0.550320</td>\n",
       "      <td>0.603894</td>\n",
       "      <td>3438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>0.782330</td>\n",
       "      <td>0.684594</td>\n",
       "      <td>0.730206</td>\n",
       "      <td>7140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>0.781841</td>\n",
       "      <td>0.651061</td>\n",
       "      <td>0.710483</td>\n",
       "      <td>6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.428332</td>\n",
       "      <td>0.283183</td>\n",
       "      <td>0.340952</td>\n",
       "      <td>6321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.686203</td>\n",
       "      <td>0.547555</td>\n",
       "      <td>0.609089</td>\n",
       "      <td>23499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              p         r         f      s\n",
       "MISC   0.669024  0.550320  0.603894   3438\n",
       "LOC    0.782330  0.684594  0.730206   7140\n",
       "PER    0.781841  0.651061  0.710483   6600\n",
       "ORG    0.428332  0.283183  0.340952   6321\n",
       "total  0.686203  0.547555  0.609089  23499"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs_train=conll_train\n",
    "hyps_train=my_conll_train\n",
    "results_train = evaluate(refs_train, hyps_train)\n",
    "pd_tbl_train = pd.DataFrame().from_dict(results_train, orient='index')\n",
    "pd_tbl_train.round(decimals=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request 2:\n",
    "#### Grouping of Entities\n",
    "Write a function to group recognized named entities using noun_chunks method of spaCy. Analyze the groups in terms of most frequent combinations (i.e. NER types that go together)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1:** **Grouping entities**\n",
    "* **input**: a list of sentences passed as string\n",
    "* **output**: a list of lists, where the inner lists have as elements the label of the entities that belongs to the same noun chunk.\n",
    "\n",
    "First, the function creates a dictionary to store the chunks of the text sentences and initializes a list (`chunk_done`) to store the entity chunks already added to the final output and a list (`group_ent`) to store the future output. \n",
    "Then the function cycles across all the sentences belongin to the text.\n",
    "The first step is to obtain a processed `Doc` of the sentence by using `nlp_spacy`. Then there are two different cycles:\n",
    "\n",
    "* The first cycle acts on the doc chunks found by the attribute `doc.noun_chunks` in that way: A list is created and for all the tokens belonging to the chunk under examination there is a check on the entity label. If the token doesn't belong to an entity or if the iob label is different from \"B\" (in other words, if the entity was already detected by the previous token belonging to it) the function skip to the next token, otherwise the entity type encountered is added to the list referred to that noun chunk. After the inspection of all the tokens of the noun chunks, each of the token is added to the `chunks` dictionary as key, and the relative value is a list containing as first element the list of the entity belonging to the token chunk and as second element the chunk containing the key token. \n",
    "* The second cycle acts on the doc entities found by the attribute `doc.ents` in that way: if the first element of the entity (the token with \"B\" iob label) is one of the keys of the dictionary and the chunk it belongs to hasn't been added yet to the list of the grouped entity (this control is made by searching for that chunk in the `chunk_done` list) the list of all the entity labels of its noun chunk (the first element of the token value in the dictionary) is added to the `group_ent` list and the relative chunk is added to the `chunk_done` list in order not to be repeated when finding the other tokens belonging to that chunk. Otherwise, if the first element of the entity doesn't appear in the dictionary keys, its entity type is added to the `group_ent` list as a single element.\n",
    "\n",
    "At the end, the list with the grouped entities is returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_entities(text):\n",
    "    chunks=dict()\n",
    "    chunk_done=[]\n",
    "    group_ent=[]\n",
    "    for sentence in text:\n",
    "        doc=nlp_spacy(sentence)\n",
    "        for chunk in doc.noun_chunks:\n",
    "            l=[]\n",
    "            for c in chunk:\n",
    "                if c.ent_type_!=\"\" and c.ent_iob_=='B':\n",
    "                    l.append(c.ent_type_)\n",
    "            for ch in chunk:\n",
    "                chunks[ch]=[l, chunk]\n",
    "        for ent in doc.ents:\n",
    "            if ent[0] in chunks.keys() and chunks[ent[0]][1] not in chunk_done:\n",
    "                group_ent.append(chunks[ent[0]][0])\n",
    "                chunk_done.append(chunks[ent[0]][1])\n",
    "            elif ent[0] not in chunks.keys():\n",
    "                group_ent.append([ent[0].ent_type_])\n",
    "    return group_ent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1: Frequency analysis**\n",
    "\n",
    "The `nbest` function will return the n more frequent grouped entities in decremental order.\n",
    "The `frequency_NER` function works in that way:\n",
    "* **input**: the list of grouped entities (output of the previous  `grouping_entities` function) and an integer n (setted equal to 100) to choose the number of elements to consider\n",
    "* **output**: the n more frequent grouped entities stored in a dictionary where the keys are the entity labels that belong to the same group and the value for each key is the number of time that the combination of that entities is found.\n",
    "For each group of entities the string representing all the entities is created. If that group hasn't been found yet the string is added to the dictionary as key and the value is setted to one. Otherwise, if the group was already in the dictionary keys, the relative value is incremented of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbest(d,n):\n",
    "    return dict(sorted(d.items(),key=lambda item: item[1],reverse=True)[:n])\n",
    "\n",
    "def frequency_NER(grouped_entity, n=100):\n",
    "    freq=dict()\n",
    "    for gr in grouped_entity:\n",
    "        string=gr[0]\n",
    "        for j in range(1,len(gr)):\n",
    "            string+=\", \"+str(gr[j])\n",
    "        if string not in freq.keys():\n",
    "                freq[string]=1\n",
    "        else:\n",
    "            freq[string]+=1\n",
    "    return(nbest(freq,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of `grouping_entities` and `frequency_NER` with a simple sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ORG', 'PERSON'], ['DATE'], ['GPE'], ['GPE']]\n",
      "{'GPE': 2, 'ORG, PERSON': 1, 'DATE': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grouping_entities([\"Apple's Steve Jobs died in 2011 in Palo Alto, California.\"]))\n",
    "print(frequency_NER(grouping_entities([\"Apple's Steve Jobs died in 2011 in Palo Alto, California\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of `frequency_NER` with the test set of CoNLL 2003 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CARDINAL': 1622, 'GPE': 1253, 'PERSON': 1069, 'DATE': 996, 'ORG': 865, 'NORP': 293, 'MONEY': 147, 'ORDINAL': 111, 'TIME': 83, 'PERCENT': 80, 'EVENT': 58, 'LOC': 54, 'CARDINAL, PERSON': 52, 'QUANTITY': 51, 'NORP, PERSON': 43, 'GPE, PERSON': 34, 'GPE, GPE': 26, 'FAC': 22, 'PRODUCT': 22, 'ORG, PERSON': 21, 'CARDINAL, ORG': 20, 'GPE, ORG': 15, 'CARDINAL, NORP': 15, 'CARDINAL, GPE': 13, 'LAW': 11, 'WORK_OF_ART': 9, 'ORG, ORG': 9, 'GPE, PRODUCT': 9, 'DATE, EVENT': 8, 'DATE, ORG': 8, 'PERSON, PERSON': 8, 'NORP, ORG': 8, 'ORG, DATE': 7, 'DATE, TIME': 7, 'LANGUAGE': 6, 'GPE, DATE': 5, 'CARDINAL, CARDINAL': 5, 'NORP, ORDINAL': 5, 'ORG, GPE': 5, 'DATE, NORP': 5, 'GPE, ORDINAL': 4, 'ORDINAL, PERSON': 4, 'GPE, CARDINAL': 4, 'ORG, NORP': 4, 'PERSON, GPE': 4, 'CARDINAL, DATE': 3, 'PERSON, ORG': 3, 'ORG, CARDINAL': 3, 'CARDINAL, PERSON, CARDINAL': 3, 'NORP, NORP': 3, 'PERSON, PERSON, PERSON': 2, 'CARDINAL, ORDINAL': 2, 'CARDINAL, CARDINAL, PERSON': 2, 'ORG, ORDINAL': 2, 'LANGUAGE, ORDINAL': 2, 'GPE, DATE, ORG': 2, 'ORDINAL, EVENT': 2, 'GPE, LOC': 2, 'CARDINAL, CARDINAL, ORG': 2, 'QUANTITY, QUANTITY': 2, 'GPE, NORP': 2, 'DATE, CARDINAL': 2, 'DATE, NORP, PERSON': 2, 'EVENT, CARDINAL': 2, 'GPE, FAC': 2, 'PERSON, CARDINAL': 2, 'ORDINAL, NORP': 1, 'GPE, PERSON, CARDINAL': 1, 'PERSON, WORK_OF_ART': 1, 'ORDINAL, DATE': 1, 'ORG, GPE, ORDINAL': 1, 'ORG, QUANTITY': 1, 'CARDINAL, GPE, GPE': 1, 'PERCENT, CARDINAL': 1, 'PERCENT, PERSON': 1, 'NORP, DATE': 1, 'PERSON, NORP': 1, 'LOC, DATE': 1, 'DATE, FAC': 1, 'CARDINAL, CARDINAL, NORP': 1, 'NORP, PERSON, DATE': 1, 'LOC, ORDINAL': 1, 'PRODUCT, GPE': 1, 'MONEY, ORG': 1, 'NORP, LOC': 1, 'ORDINAL, GPE': 1, 'MONEY, DATE': 1, 'CARDINAL, PERCENT': 1, 'DATE, WORK_OF_ART': 1, 'MONEY, MONEY': 1, 'MONEY, CARDINAL, CARDINAL, ORG': 1, 'CARDINAL, GPE, TIME': 1, 'FAC, GPE': 1, 'ORG, WORK_OF_ART': 1, 'GPE, ORDINAL, PERSON': 1, 'CARDINAL, LOC': 1, 'PERSON, MONEY': 1, 'MONEY, PRODUCT': 1, 'DATE, PERSON': 1, 'PERSON, GPE, CARDINAL': 1}\n"
     ]
    }
   ],
   "source": [
    "group=grouping_entities(sentences_test)\n",
    "print(frequency_NER(group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request 3:\n",
    "One of the possible post-processing steps is to fix segmentation errors. Write a function that extends the entity span to cover the full noun-compounds. Make use of compound dependency relation.\n",
    "* **input**: a token\n",
    "* **output**: a tuple whose first element is a list with the structure ready to be taken as input by the function `spacy_to_conll` defined above and the second element is the head of the token if the token dependency is equal to compound and the token appears before its head in the sentence. This is done to change properly the iob label of the compound span. In fact, if the token is located before its head to consider it part of the entity its iob label will be assigned to \"B\" and, consequently, its head will be re-labelled to be one of the \"I\" iob label of the entity span. The eventual re-labelling is done by the function `spacy_to_conll` defined above and the behaviour of the re-labelling is made clear in that section. Instead, if the considered token has a compund dependency but it appears after its head, the function return a new list (always with the structure ready to be taken as input by `spacy_to_conll` where, in the position referred to the iob label the new label is \"I\", and in the position referred to the entity type of the token (before empty) the entity of the token it has a compund dependency with is insert. If the token has not a compound dependency, the function only creates the right input for `spacy_to_conll`. In both the last two cases, the second element of the tuple is \"None\" because no re-labelling of the head need to be done by `spacy_to_conll`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compound(token):\n",
    "    if token.dep_=='compound' and token.ent_type_=='':\n",
    "        if token.head.i<token.i:\n",
    "            post_compound=([token.text,\"I\",token.head.ent_type_,token],None)\n",
    "        else:\n",
    "            post_compound=([token.text,\"B\",token.head.ent_type_,token],token.head)\n",
    "    else:\n",
    "        post_compound=([token.text,token.ent_iob_,token.ent_type_,token],None)\n",
    "    return post_compound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we try to see how fixing the compound dependency can influence the accuracy, the precision, the recall and the f-measure of the CoNLL 2003 test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_conll_test_compound=my_conll(sentences_test,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.458458</td>\n",
       "      <td>0.275738</td>\n",
       "      <td>0.344361</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>0.637562</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.591291</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>0.727152</td>\n",
       "      <td>0.658273</td>\n",
       "      <td>0.691001</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>0.698855</td>\n",
       "      <td>0.604205</td>\n",
       "      <td>0.648093</td>\n",
       "      <td>1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.646876</td>\n",
       "      <td>0.516997</td>\n",
       "      <td>0.574690</td>\n",
       "      <td>5648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              p         r         f     s\n",
       "ORG    0.458458  0.275738  0.344361  1661\n",
       "MISC   0.637562  0.551282  0.591291   702\n",
       "LOC    0.727152  0.658273  0.691001  1668\n",
       "PER    0.698855  0.604205  0.648093  1617\n",
       "total  0.646876  0.516997  0.574690  5648"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs_test=conll_test\n",
    "hyps_test_compound=my_conll_test_compound\n",
    "results_test_compound = evaluate(refs_test, hyps_test_compound)\n",
    "pd_tbl_test_compound = pd.DataFrame().from_dict(results_test_compound, orient='index')\n",
    "pd_tbl_test_compound.round(decimals=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.899946161300743\n"
     ]
    }
   ],
   "source": [
    "accuracy_token(my_conll_test_compound,conll_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
